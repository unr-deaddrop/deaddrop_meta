"""
Base definitions for protocols and the DeadDrop standard message format.

TODO: In the distant future, this should be its own library. It is being included
with the Pygin distribution since we currently don't *have* another agent type.
Important to note is that this being its own library doesn't need to happen
for the server to work, since everything should be exported as a JSON by any
agent anyways.

This library must not import any other internal libraries; it may only import
the standard library and external packages.

Each protocol is implemented as a subclass of ProtocolBase, an abstract class
containing several properties that may (or may not) be defined.

The available protocols for a particular agent are determined by inspecting all
available subclasses of ProtocolBase.

When a protocol depends on some external library or binary, it is assumed to be
managed *outside* of the Python environment; that is, it does not need to be
installed as part of the normal Python environment setup process, and can be
handled by an initial setup script at the OS level.
"""

from base64 import b64encode, b64decode
from datetime import datetime
from enum import Enum
from textwrap import dedent
from typing import Any, Type, Optional, ClassVar, Union
from typing_extensions import Annotated
import abc
import configparser
import logging
import uuid
import json

from pydantic import (
    BaseModel,
    Field,
    field_serializer,
    field_validator,
    Discriminator,
    Tag,
    ValidationError,
)

from deaddrop_meta.argument_lib import ArgumentParser


class DeadDropMessageType(str, Enum):
    """
    String enumeration of all available message types.
    """

    # Message generated in response to a command. Messages of this type are only
    # ever generated by agents.
    CMD_RESPONSE = "command_response"

    # Message generated as a request for an agent to execute a command. Messages
    # of this type are only ever generated by agents.
    CMD_REQUEST = "command_request"

    # One or more log entries generated by an agent. One log bundle may contain
    # one or more underlying log messages, reducing the frequency with which
    # messages are sent.
    LOG_BUNDLE = "log_bundle"

    # Heartbeat message generated by an agent. May contain additional diagnostic
    # data.
    HEARTBEAT = "heartbeat"


class DeadDropLogLevel(int, Enum):
    """
    String enumeration of all recognized logging levels.

    These are identical in name and value to Python's `logging` modules.
    This enforces the log levels across every DeadDrop agent implementation,
    including those that are not written in Python.

    Note that the logging.NOTSET level is excluded, as it has no significance
    outside of implementation.
    """

    DEBUG = logging.DEBUG
    INFO = logging.INFO
    WARNING = logging.WARNING
    ERROR = logging.ERROR
    CRITICAL = logging.CRITICAL


class LogMessage(BaseModel):
    """
    An individual log message.

    The fields of this model are consistent with
    """

    # The level of the log message.
    level: DeadDropLogLevel

    # The actual log message itself.
    data: str

    # The timestamp that this log was generated. This is different from the
    # timestamp of the log bundle.
    timestamp: datetime

    # If associated with a task, the actual task ID for this log message. If
    # not associated with a task (e.g. it's an overhead debug message), this
    # is null.
    task_id: Optional[uuid.UUID]

    # The "category" of the log. This is intended for agent-specific categorization
    # of individual logs, which may be used to filter the logs exported from the
    # agent.
    category: Optional[str]


class DeadDropMessagePayload(BaseModel, abc.ABC):
    # Require all payload types to define a message_type. Pydantic does not
    # really support the idea of an interface using `abc` and then requiring
    # models to define them as static variables (it raises a warning if you do),
    # so the method described at https://github.com/pydantic/pydantic/discussions/2410
    # is used instead.
    @property
    @abc.abstractmethod
    def message_type(self) -> DeadDropMessageType:
        pass


class CommandResponsePayload(DeadDropMessagePayload):
    message_type: ClassVar[DeadDropMessageType] = DeadDropMessageType.CMD_RESPONSE

    # The name of the command executed.
    cmd_name: str

    # The start and finish time of the command, as measured by an agent's own
    # command module.
    start_time: datetime
    end_time: datetime

    # The UUID of the original command_request message that caused this command
    # to execute.
    request_id: uuid.UUID

    # The underlying result, an arbitrary dictionary of strings to JSON serializable
    # values. The dictionary should generally not be empty, but this is not
    # explicitly disallowed.
    result: dict[str, Any]


class CommandRequestPayload(DeadDropMessagePayload):
    message_type: ClassVar[DeadDropMessageType] = DeadDropMessageType.CMD_REQUEST

    # The agent-specific name of the command to execute.
    cmd_name: str

    # The actual arguments passed to the command.
    cmd_args: dict[str, Any]


class LogBundleFilters(BaseModel):
    """
    Commonly identified log bundle filter options. These may be included as part
    of a command request to reduce the scope of the logs exported by agents when
    explicitly instructed to.
    """

    # The time ranges to match. Both inclusive (to the precision available).
    min_time: Optional[datetime]
    max_time: Optional[datetime]

    # The logging level to match. Both inclusive.
    min_level: Optional[DeadDropLogLevel]
    max_level: Optional[DeadDropLogLevel]

    # The category to match.
    category: Optional[str]

    # The task ID to match.
    task_id: Optional[uuid.UUID]


class LogBundlePayload(DeadDropMessagePayload):
    message_type: ClassVar[DeadDropMessageType] = DeadDropMessageType.LOG_BUNDLE

    # The list of all log messages associated with this bundle.
    logs: list[LogMessage]

    # Arbitrary data that may be included with the log bundle. This is agent-specific
    # and is not expected to be used in serverside calculations.
    extra: dict[str, Any]

    # The standard filters applied to this log bundle, if any.
    filters: Optional[LogBundleFilters]


class HeartbeatPayload(DeadDropMessagePayload):
    message_type: ClassVar[DeadDropMessageType] = DeadDropMessageType.HEARTBEAT

    # Any extra diagnostic information that the agent wants to include with the
    # heartbeat. This is agent-specific and is not expected to be used in
    # serverside-calculations.
    extra: dict[str, Any]


def get_payload_discriminator_value(v: Any) -> str:
    """
    Retrieve the class variable or dictionary element associated with the discriminator.

    This uses the technique identical to Pydantic's documentation:
    https://docs.pydantic.dev/latest/concepts/unions/#discriminated-unions-with-callable-discriminator
    """
    try:
        if isinstance(v, dict):
            return v.get("message_type")  # type: ignore[return-value]

        return getattr(v, "message_type")
    except AttributeError:
        # Note that Pydantic uses its own validation error (along the lines of
        # "union tag not found", so this error message is unused)
        raise ValidationError("message_type missing from payload")


class DeadDropMessage(BaseModel, abc.ABC):
    """
    Class representing the basic definition of a DeadDrop message.

    All messages contain the following information:
    - One of five standard message types (dictated by DeadDropMessageType).
    - The server-side user ID associated with the message, if any, for
      accountability purposes.
    - The ID of the agent where the message originated from. If the message
      is forwarded, this contains the ID of the original agent that constructed
      this message. If the message originates from the server, this is empty.
    - The ID of the message, a UUID.
    - The timestamp of the message.
    - The digest of the message, intended to be a digital signature. The agent
      stores its own private key and the public key of the server; the server
      stores its own private key and the public key of the agent. It is important
      to note that the agent's private key is not protected from discovery; it is
      therefore possible to forge valid messages originating from a particular agent.
      This weakness is outside the intended scope of this project.
    - A "payload" field, which contains the actual payload of the message. The
      payload is another JSON dictionary that varies in sturcture depending on
      the message type.

    The fragmentation, encryption, and verification of these messages may be
    delegated to lower-level protocols. It is best to generally treat this message
    as part of the application layer, and the protocols as the transport layer.

    That said, these messages provide an innate signing field to include a
    digital signature; how these signatures are created is up to the agent
    and the server to decide.

    In the future, these messages may be wrapped in another JSON object containing
    forwarding information, effectively allowing it to be routed (as if it were
    at the networking layer). This is not planned in the short term.
    """

    # The UUID of the message. If not set at construct time, it is set
    # to a random value (i.e. uuidv4).
    message_id: uuid.UUID = Field(default_factory=uuid.uuid4)

    # The user this message is associated with. May be null if not associated
    # with a user.
    user_id: uuid.UUID = Field(default_factory=lambda: uuid.UUID(int=0))

    # The agent ID, or null if sent by the server.
    source_id: uuid.UUID = Field(default_factory=lambda: uuid.UUID(int=0))

    # The timestamp that this message was created. Assume UTC.
    timestamp: datetime = Field(default_factory=datetime.utcnow)

    # The payload of the underlying message type. Four built-in message types with
    # well-defined payload structures are inherently provided by the framework.
    payload: Annotated[
        Union[
            Annotated[CommandRequestPayload, Tag(DeadDropMessageType.CMD_REQUEST)],
            Annotated[CommandResponsePayload, Tag(DeadDropMessageType.CMD_RESPONSE)],
            Annotated[LogBundlePayload, Tag(DeadDropMessageType.LOG_BUNDLE)],
            Annotated[HeartbeatPayload, Tag(DeadDropMessageType.HEARTBEAT)],
        ],
        Discriminator(get_payload_discriminator_value),
    ]

    # Digital signature, if set.
    digest: bytes | None = None

    # I've decided to let Pydantic handle this for any Python components, which 
    # is every part of the project right now. Converting from ISO 8601 for anything
    # that doesn't use Pydantic is that module's problem.
    #
    # This also fixes the concern with accidental rounding and imprecision when 
    # calculating the signature (hopefully).

    # @field_serializer("timestamp", when_used="json-unless-none")
    # @classmethod
    # def serialize_timestamp(cls, timestamp: datetime, _info):
    #     """
    #     On JSON serialization, the timestamp is always numeric.
    #     """
    #     return timestamp.timestamp()

    # @field_validator("timestamp", mode="before")
    # @classmethod
    # def validate_timestamp(cls, v: Any) -> datetime:
    #     """
    #     Convert a timestamp back to a native Python datetime object.
    #     """
    #     if type(v) is datetime:
    #         return v

    #     if type(v) is str:
    #         try:
    #             return datetime.utcfromtimestamp(float(v))
    #         except Exception as e:
    #             raise ValueError(
    #                 f"Assumed string timestamp conversion of {v} failed."
    #             ) from e

    #     if type(v) is float:
    #         try:
    #             return datetime.utcfromtimestamp(v)
    #         except Exception as e:
    #             raise ValueError(
    #                 f"Attempted timestamp conversion of {v} failed."
    #             ) from e

    #     raise ValueError("Unexpected type for timestamp")

    @field_serializer("digest", when_used="json-unless-none")
    @classmethod
    def serialize_digest(cls, digest: bytes, _info):
        """
        On JSON serialization, the digest is base64.

        This differs from the "actual" Pydantic behavior of using \u encoding.
        """
        return b64encode(digest).decode("utf-8")

    @field_validator("digest", mode="before")
    @classmethod
    def validate_digest(cls, v: Any) -> bytes | None:
        """
        On validation, the digest should be bytes. If it's a string,
        assume it's base64.
        """
        if v is None:
            return None

        if type(v) is str:
            return b64decode(v)

        if type(v) is bytes:
            return v

        raise ValueError("Unexpected type for digest")


class ProtocolConfig(BaseModel, abc.ABC):
    @property
    @abc.abstractmethod
    def section_name(self) -> str:
        """
        The configuration "section" used in configuration files.

        This MUST be the same as the module name.
        """
        pass

    @property
    @abc.abstractmethod
    def dir_attrs(self) -> list[str]:
        """
        A list of attributes that represent directories that need to be created
        at runtime.
        """
        pass

    @property
    @abc.abstractmethod
    def checkin_interval_name(self) -> str:
        """
        The config key/attribute that contains the checkin interval for this
        protocol.
        """
        pass

    def get_checkin_interval(self) -> int:
        """
        The checkin interval for this protocol.
        """
        return getattr(self, self.checkin_interval_name)

    def create_dirs(self) -> None:
        """
        Create any associated directories.
        """
        for field in self.dir_attrs:
            getattr(self, field).resolve().mkdir(exist_ok=True, parents=True)

    @classmethod
    def from_cfg_parser(cls, cfg_parser: configparser.ConfigParser) -> "ProtocolConfig":
        # Property, always returning string.
        try:
            cfg_obj = cls.model_validate(cfg_parser[cls.section_name])  # type: ignore[index]
        except KeyError as e:
            raise RuntimeError(
                f"Missing configuration section for protocol {cls.section_name}, is it defined?"
            ) from e
        cfg_obj.create_dirs()
        return cfg_obj


class ProtocolArgumentParser(ArgumentParser, abc.ABC):
    @classmethod
    def from_config_obj(cls, config: ProtocolConfig) -> "ProtocolArgumentParser":
        """
        Generate an argument parser from a ProtocolConfig object, setting
        the values from the ProtocolConfig object.
        """
        arg_obj = cls()
        if not arg_obj.parse_arguments(config.model_dump()):
            raise ValueError(f"{config} did not fill the required arguments for {cls}")

        return arg_obj


class ProtocolBase(abc.ABC):
    """
    Abstract base class representing the standard definition of a protocol
    for Python-based agents.
    """

    @property
    @abc.abstractmethod
    def name(self) -> str:
        """
        The internal protocol name displayed to users and used in internal
        messaging.

        It is preferred that this is a valid Python variable name for future
        compatibility.
        """
        pass

    @property
    @abc.abstractmethod
    def version(self) -> str:
        """
        The version string for this protocol implementation.
        """
        pass

    @property
    @abc.abstractmethod
    def description(self) -> str:
        """
        A brief description of this protocol, to be displayed to users (primarily)
        through the web interface.
        """
        pass

    @property
    @abc.abstractmethod
    def config_model(self) -> Type[BaseModel]:
        """
        The model used to represent the configurable elements of this protocol
        on each call.
        """
        pass

    @classmethod
    @abc.abstractmethod
    def send_msg(cls, msg: DeadDropMessage, args: dict[str, Any]) -> dict[str, Any]:
        """
        Send an arbitrary binary message.

        This function should implement any mechanisms needed to split messages,
        place messages at an agreed-upon location, and so on. If any additional
        paramters are required for this to function, such as the credentials
        needed to access the account used for transferring information, they
        may be passed as protocol-specific keyword arguments.

        This function may raise exceptions.

        The return value of this function is always a dict, but the underlying
        structure may be anything; it is up to the agent core to decide how to
        handle the responses of a particular protocol implementation.

        :param msg: The binary message to send.
        """
        pass

    @classmethod
    @abc.abstractmethod
    def get_new_messages(cls, args: dict[str, Any]) -> list[DeadDropMessage]:
        """
        Retrieve all new messages that have yet to be retrieved.

        This function should make a best-effort attempt at ensuring that messages
        that have already been retrieved in the past are not retrieved again.
        However, it is up to the server or agent to ensure that it is not
        acting on duplicated messages, since a message may have been sent over
        more than one protocol.

        Diagnostic data as a result of retrieving the messages should be logged;
        it is not returned as part of the return value.

        If additional arguments are required for this to operate, such as the
        credentials needed to log onto an account or a shared meeting, they
        may be passed as either a configuration object or keyword arguments.

        This function may raise exceptions, such as if a service is inaccessible.
        """
        pass

    def to_dict(self) -> dict[str, Any]:
        """
        Return this protocol's metadata as a dictionary.

        Note that for compatibility purposes, ensure that the resulting dictionary
        is completely JSON serializable.
        """
        return {
            "name": self.name,
            "description": dedent(self.description).strip(),
            "version": self.version,
            "config": self.config_model.model_json_schema(),
        }


def export_all_protocols() -> list[Type[ProtocolBase]]:
    """
    Return a list of visible protocol classes.

    The protocol lookup occurs by inspecting all available subclasses of ProtocolBase
    when this function is executed.

    Note that "visible" means that the associated subclasses of ProtocolBase must
    already have been imported. If you implement a script to generate the command JSONs,
    you will need to import the commands ahead of time.
    """
    return ProtocolBase.__subclasses__()


def export_all_protocol_configs() -> list[Type[ProtocolConfig]]:
    """
    Return a list of visible protocol configuration objects.

    Refer to export_all_protocols() above.
    """
    return ProtocolConfig.__subclasses__()


def get_protocols_as_dict() -> dict[str, Type[ProtocolBase]]:
    """
    Return a dictionary of commands, suitable for lookup.

    The keys are the `name` attribute of each command found; the values are the
    literal types for each command (a subclass of CommandBase).
    """
    # mypy doesn't handle properties well; this works in practice, and the type
    # of cmd.name is *always* str
    return {proto.name: proto for proto in export_all_protocols()}  # type: ignore[misc]


def lookup_protocol(protocol_name: str) -> Type[ProtocolBase]:
    """
    Search for a provided protocol.
    """
    try:
        return get_protocols_as_dict()[protocol_name]
    except KeyError:
        raise RuntimeError(
            f"Failed to find protocol {protocol_name}, either it doesn't exist or it isn't visible"
        )


def export_protocols_as_json(protocol_classes: list[Type[ProtocolBase]], **kwargs):
    """
    Return a nicely formatted string containing all command information,
    suitable for presentation in the DeadDrop interface.
    """
    json_objs: list[dict[str, Any]] = []
    for command_class in protocol_classes:
        json_objs.append(command_class().to_dict())

    return json.dumps(json_objs, **kwargs)
